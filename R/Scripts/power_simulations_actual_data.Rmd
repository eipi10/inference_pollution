---
title: "Power Simulation Exercise: actual data"
author:
  - name: Vincent Bagilet 
    url: https://www.sipa.columbia.edu/experience-sipa/sipa-profiles/vincent-bagilet
    affiliation: Columbia University
    affiliation_url: https://www.columbia.edu/
  - name: Léo Zabrocki 
    url: https://www.parisschoolofeconomics.eu/en/
    affiliation: Paris School of Economics
    affiliation_url: https://www.parisschoolofeconomics.eu/en/
date: "`r Sys.Date()`"
output: distill::distill_article
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE, results='hide', warning=FALSE}
library(knitr)
opts_chunk$set(fig.path = "images/",
               cache.path = "cache/",
               cache = FALSE,
               echo = TRUE, #set to false to hide code
               message = FALSE,
               warning = FALSE,
               out.width = "85%",
               dpi = 200,
               fig.align = "center")  
```  

# Purpose of the document

In this document, we carry out a simulation exercise to evaluate the performance of Randomized Control Trials (RCTs), Difference-In-Differences (DiDs), Regression Discontinuity Designs (RDDs) and Interrupted Time Series (ITS) "methods" in measuring the short-term effects of air pollution on health. 

Results are analysed and discussed in another document.

# Description of the analysis

## Data

We use data from 18 cities in France over the 2013-2018 period. The data set contains records of hospital admissions and deaths, mean concentration data for various air pollutants, a bunch of weather variables and calendar control variables (such as school holidays for instance). All variables are at the daily and city level. There is therefore a unique observation per date and per city in the data set.

## Background on selected designs for air pollution analyses

### RCT

Here, we consider interventions leading to changes in air pollution levels on some random days. Examples of such interventions include transportation strikes for instance. Of course, dates are often not defined as random and are likely to be correlated with unobserved variable. In the present setting, we first consider the golden standard case in which these days are defined at random. Then, we consider deviations from this golden standard.

The overall idea of the RCT is to compare the average number of deaths or hospital admissions in cities with treatment to cities with no treatment on the same day, controlling for differences across cities.

### DID

Here, we consider interventions leading to changes in air pollution levels in a subset of cities after a given date. Examples of such interventions include an air pollution reduction policy at a sub-national level or a change in regulations at a sub-national level leading to an increase in pollution level. 

The overall idea of the DID is to compare the average number of deaths or hospital admissions in cities with treatment to cities with no treatment on the same day, controlling for differences across cities.

### ITS

Here consider interventions leading to changes in air pollution levels in a subset of cities after a given date. Examples of such interventions include an air pollution reduction policy at a sub-national level or a change in regulations at a sub-national level leading to an increase in pollution level. 

The overall idea of the ITS is to compare the average number of deaths or hospital admissions before and after treatment.

### RDD

Here consider interventions that affect exposure to air pollution when air pollution levels reach a given threshold. Examples of such interventions include air pollution alerts: when pollution reaches a certain level, alerts are released, inviting people to reduce their exposure.

The overall idea of the RDD is to compare days just below the threshold to days just above the threshold (where exposure and health impacts are thus lower). The assumption is that days just below and just above the threshold are comparable.

## Analysis

### Overall setting

To sum up the analysis, the aim is to measure the performance of different designs in recovering the true effect of a treatment and to analyze characteristics of the estimates. For simplicity, consider the daily number of death as the output variable of interest for now. To do so, we proceed as follows:

1. We define the length of the study period, *ie* the number of observations, and draw a study period randomly.
1. We define the treated days. In the case of the RCT, we draw $n_{obs} \times p_{treat}$ treated days, where $p_{treat}$ is the proportion of treated days. For the ITS, we draw the date at which the treatment starts. For the RDD, we define the concentration threshold above which observations are treated. For the DiD, we define the group of treated cities.
1. We choose a true effect size, $\beta_0$, representing the percentage change in the number of deaths in response to the treatment.
1. We create fake death counts ($Y_{obs}$), accounting for the "true" effect of the treatment:  
$Y_{obs} = h_{ct}^{fake} = (1 + \beta_0 T_{ct}) h_{ct}$ where $h_{ct}$ represents the daily number of deaths or emergency admissions, for a given city $c$ at time $t$, $T_{ct}$ the treatment variable which is equal to 1 if the city $c$ is treated at time $t$ and zero otherwise. 
1. We estimate our model and retrieve $\hat{\beta}$ and the associated p-value.
1. We run the steps 4 to 6 $n_{iter}$ times and compare our estimated effects $\hat{\beta}$ to the true effect $\beta_0$. We compute the average bias, type M, type S and power.

In the potential outcome framework, we have $Y_{ct}(0)$, the number of deaths if a city $c$ is not treated at time $t$ equal to $h_{ct}$ and $Y_{ct}(1)$, the number of deaths if this city is treated, equal to $(1 + \beta_0)h_{ct}$. We build our setting, so that we can "observe" both outcomes. The estimation is performed on the fake observed data $Y_{obs} = h^{fake}$ and we have
$Y_{obs} = Y(0) × (1-T) + Y(1) × T$. 

### Varying "parameters"

Note that there are several parameters we can vary in order to evaluate the performance of the different methods: the identification strategy, the number of observations, the proportion of treated days, the true effect size and the model. In order to limit the number of simulations and for clarity, we only modify one parameter at the time, keeping others constant. We consider the following values for these parameters:

- Identification strategy: RCT, DID, RDD (we can use several pollutants to trigger the alerts), ITS
- Number of observations: we actually vary the length of the study, in days. The number of observations is approximately equal to the number of days in the study times the number of cities. We consider 100, 250, 500, 750 and 1000 days **because** ...
- Proportion of treated days: 0.1, 0.5. The proportion of days treated matters since, while the number of observations can be large, the number of treated days may remain very small (*eg* the number of strikes). We choose these values **because** ...
- Effect size: 0.15%, 0.5% and 1% **because** ...
- The estimation model: we first do not include covariates, only fixed effects. We then include include different sets of covariates.

### Deviation from the ideal case

In addition to considering an "ideal" case in which treatment is allocated randomly, the effect of the treatment is homogeneous and with perfect compliance, we can consider deviations from this "ideal" case:

```{r table2, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
table_cases <- "
| Allocation                  | Compliance   | Effect of the treatment  |
|-----------------------------|:------------:|-------------------------:|
| Random                      | Yes          | Homogeneous              |
| Random                      | No           | Homogeneous              |
| Correlated with covariates  | Yes          | Homogeneous              |
| Random                      | Yes          | Heterogeneous            |
"
cat(table_cases) 
```

- A non-random allocation can exist in several ways. The treatment can be correlated with one covariate, another or even several covariates. It can also be correlated with this covariates in different ways: linear or a large variety of non linear ways. Even with a settled correlation form, the intensity of the correlation can vary.
- The heterogeneity in the treatment effect can arise from variation with time, with individuals or given the value of covariates.

Deviating from the ideal case therefore yields a very large number of cases. We limit ourselves to a sample of these cases.

# Actual implementation

In this section, we follow the steps described in the section "analysis" and carry out our analysis. We basically define a function for each step.

## Loading and Formatting Data

We load the packages and the data and wrangle it into a format well suited for this analysis.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(here) # for files paths organization
library(tidyverse) # for data manipulation and visualisation
library(modelr) # modeling within the tidyverse
library(retrodesign) # formulas for type-m and type-s errors
library(knitr) # for tables
library(broom)
library(lubridate)
library(lmtest)
library(sandwich)
library(tictoc)
library(rlang)
library(readr)
library(fixest)
library(Formula)
library(furrr) # for parallel computing
future::plan(multicore)
library(mediocrethemes)

source(here::here("R", "Scripts", "script_custom_ggplot_theme.R"))

set_mediocre_all()
```


```{r include=FALSE}
pollution_data <- readRDS(here::here("R", "Outputs", "data_daily_imputed.rds")) %>% 
  ungroup() %>% 
  mutate(
    city = tolower(city),
    city = str_remove_all(city, "[\\s-]")
  )
emergency_data <- readRDS(here::here("R", "Outputs", "emergency_data.rds"))
mortality_data <- readRDS(here::here("R", "Outputs", "mortality_data.rds"))

total_data <- pollution_data %>% 
  left_join(emergency_data, by = c("city", "date")) %>% 
  left_join(mortality_data, by = c("city", "date")) %>% 
  ungroup() %>% 
  mutate(
    date = ymd(date),
    city = as.factor(city), 
    month = as.factor(month(date)), 
    day_of_week = as.factor(wday(date)), 
    year = as.factor(year(date))
  ) %>% 
  filter(date < "2016-01-01") 
```

## Function definitions

### Drawing the study period

First, we create a function to randomly draw a study period of a given length. For simplicity, we choose to have the same study period for each city. This also seems realistic; a study focusing on several cities would probably consider a unique study period. 

This function randomly selects a starting date for the study, early enough so that the study can actually last the number of days chosen, and returns a boolean vector indicating whether each date is in the study or not.

```{r}
draw_study_period <- function(dates, n_days_study = 200) {
  max_date <- max(dates)
  min_date <- min(dates)
  
  begin_study <- sample(seq.Date(min_date, max_date - n_days_study, "day"), 1)
  end_study <- begin_study + n_days_study
  
  dplyr::between(dates, begin_study, end_study)
}
```

### Defining the treatment

Then, we create a function to draw the treatment. This function returns a boolean vector, stating whether each observation is in the treatment group or not.

For each treatment, we define the proportion of treated units (`p_treat`). 
- For the DiD, to simplify, we set the beginning of the treatment as the median date. To get the desired proportion of treated units, we thus need to draw 2*`p_treat` cities.
- For the RDD, we draw a threshold position (from a beta distribution, for no reason). For each city, we find the corresponding threshold and define a bandwidth such that `p_treat` observations of the total sample are treated. Observations outside the bandwidth get a `NA` for `treated`. Thus, after calling this function, we need to filter out observations with a `NA` for `treated`.
- For the GAM and IV, we only consider a subset of observations to create variation across observations

```{r}
draw_treated_days <- function(data, p_treat = 0.5, treatment_type = "RCT") {
  
  if (treatment_type == "RCT") {
    treated <- rbernoulli(length(data[["date"]]), p_treat)
  } else if (treatment_type == "ITS") {
    treated <- (as.numeric(data[["date"]]) >= quantile(as.numeric(data[["date"]]), 1 - p_treat))
  } else if (treatment_type %in% c("GAM", "IV")) {
    # treated <- TRUE
    treated <- rbernoulli(length(data[["date"]]), p_treat)
    treated <- ifelse(treated, treated, NA) 
  } else if (treatment_type == "DID") {
    treated_cities <- unique(data[["city"]]) %>%
      sample(size = round(length(.) * min(p_treat * 2, 1)))
    treated <- (data[["city"]] %in% treated_cities &
                  data[["date"]] >= median(data[["date"]]))
  } else if (str_starts(treatment_type, "RDD")) {
    pollutant <- str_extract(treatment_type, "(?<=_).+")
    threshold_pos <- rbeta(1, 20, 2)
    treated <- data %>%
      group_by(.data$city) %>%
      mutate(
        threshold = quantile(.data[[pollutant]], threshold_pos, names = FALSE),
        treated = (.data[[pollutant]] >= unique(threshold)),
        bw = cut_width(
          .data[[pollutant]],
          width = length(.) * 2 * p_treat,
          center = unique(threshold)
        ),
        treated = ifelse(
          threshold > as.numeric(str_extract(bw, "([:digit:]|\\.|-)+(?=,)")) &
            threshold < as.numeric(str_extract(bw, "(?<=,)([:digit:]|\\.)+")), treated, NA)
      ) %>%
      ungroup() %>%
      .$treated
  }
  
  return(treated)
  # data <- data %>% mutate(treated = treated)
  # return(data)
}
```

Both to verify that everything works well and for illustration, we can make quick plots:

```{r include=FALSE}
test_treatment_data <- total_data %>% 
  mutate(study_period = draw_study_period(date, 500)) %>% 
    filter(study_period) %>%
    select(-study_period) %>%
    mutate(
      treated_RCT = draw_treated_days(., 0.2, "RCT"),
      treated_ITS = draw_treated_days(., 0.2, "ITS"),
      treated_RDD = draw_treated_days(., 0.2, "RDD_pm10"),
      treated_DID = draw_treated_days(., 0.2, "DID"), 
      city = str_to_title(city)
    ) 

graph_treatment_assignment <- function(data, method) {
  data %>% 
    rename(Treated = .data[[paste("treated", method, sep = "_")]]) %>% 
    ggplot() +
    geom_point(aes(x = date, y = pm10, color = Treated), size = 0.3) +
    facet_wrap(~city) +
    labs(
      title = paste("Treatment assignation for", method), 
      subtitle = "Evolution of PM10 concentration in time for each city",
      x = "Date", 
      y = "PM10 concentration level (in mug/m3)"
    )
} 

test_treatment_data %>% 
  graph_treatment_assignment("RCT")

test_treatment_data %>% 
  graph_treatment_assignment("RDD")

test_treatment_data %>% 
  graph_treatment_assignment("DID")

test_treatment_data %>% 
  graph_treatment_assignment("ITS")

```

### Creating the output if a unit is treated

We then create the output if a unit is treated, Y(1).

```{r}
create_y1 <- function(dep_var, percent_effect_size = 0.5, treatment_type = "RCT", pollutant = NULL) {
  # y1 <- output_var*(1 + percent_effect_size/100)
  if (str_starts(treatment_type, ("RDD|RCT|DID|ITS"))) {
    y1 <- dep_var + rpois(length(dep_var), dep_var*percent_effect_size/100) %>% suppressWarnings()
  } else if (treatment_type == "GAM") {
    y1 <- dep_var + rpois(length(dep_var), pollutant*percent_effect_size/100) %>% suppressWarnings()
  }
  return(y1)
} 
```

### Estimate the model

We can then estimate our model and retrieve the point estimate and p-value.
The model should be specified in a three part formula as follows: y ~ x | fixed effects | cluster. If one does not want to set fixed effects, a 0 should be put in the second part of the formula: y ~ x | 0 | cluster.

```{r}
estimate_model <- function(data, formula) {
  #get the different parameters from the formula
  fml <- Formula::as.Formula(formula)
  cluster <- formula(fml, lhs = 0, rhs = 3) %>% 
    suppressWarnings() #when no cluster provided, warning
  actual_fml <- formula(fml, rhs = -3)
  se <- ifelse(cluster == ~0, "hetero", "cluster")  
  
  #run the estimation
  est_results <- data %>% 
    feols(
      data = ., 
      fml = actual_fml, 
      cluster = cluster,
      se = se
    ) 
  
  #retrieve the usefull info
  nobs <- length(est_results$residuals)
  
  est_results %>%
    broom::tidy(conf.int = TRUE) %>%
    filter(
      term %in% c(
        "treatedTRUE", 
        "postTRUE:city_treatedTRUE", "city_treatedTRUE:postTRUE"
      )) %>%
    rename(p_value = p.value) %>%
    mutate(estimate = estimate) %>%
    select(estimate, p_value) %>%
    mutate(n_obs = nobs)
} 
```

### Computing simulations

We then create a function running all the previous functions together and therefore performing an iteration of the simulation for a given set of parameters. This function returns a one row data set with estimate, p-value, number of observations and true effect size.

```{r}
compute_simulation <- function(data, n_days_study = 200, p_treat = 0.5, treatment_type = "RCT", percent_effect_size = 0.5, formula = "deaths_all_causes ~ treated") {
  
  fml <- Formula::as.Formula(formula)
  dep_var <- paste(fml[[2]])
  
  sim_data <- data %>% 
    mutate(study_period = draw_study_period(date, n_days_study)) %>% 
    filter(study_period) %>%
    select(-study_period) %>%
    mutate(
      treated = draw_treated_days(., p_treat, treatment_type),
      # true_treated = draw_treated_days(., p_treat, treatment_type),
      y0 = .data[[dep_var]],
      y1 = create_y1(.data[[dep_var]], percent_effect_size),
      yobs = y1*treated + y0*(1 - treated)
      # yobs = y1*true_treated + y0*(1 - true_treated)
    ) %>% 
    filter(!is.na(treated)) #not necessary bc dropped in lm()
    # filter(!is.na(true_treated)) #not necessary bc dropped in lm()
  
  #for DID, need a post and a city_treated variable
  if(treatment_type == "DID") {
    sim_data <- sim_data %>%
      group_by(city) %>%
      mutate(city_treated = as.logical(max(treated))) %>%
      ungroup() %>%
      group_by(date) %>%
      mutate(post = as.logical(max(treated))) %>%
      ungroup()
  }

  #for ITS, need a time index and time index
  if(treatment_type == "ITS") {
    sim_data <- sim_data %>%
      group_by(city) %>%
      mutate(
        t = as.numeric(date) - min(as.numeric(date)),
        t_post = max(0, as.numeric(date) - as.numeric(min(.data$date[treated == TRUE])))
      ) %>%
      ungroup()
  }

  sim_output <- sim_data %>%
    estimate_model(formula = update(fml, yobs ~ .)) %>%
    mutate(true_effect = mean(sim_data$y1 - sim_data$y0, na.rm = TRUE))
  
  return(sim_output)
} 

test <- total_data %>%
  compute_simulation(formula = "deaths_na_causes ~ post:city_treated", n_days_study = 700, treatment_type = "DID") 
````

We will then loop this function to get a large number of replications of each simulation for a given set of parameters. We will also vary the values of the different parameter.

## Running the simulations

We can then run the simulations. But first, we define the set of parameters we want to consider.

### Defining the parameters

We create a table displaying in each row a set of parameters we want to have a simulation for, `sim_param`. We will then map our function `compute_simulation` on this table.

To build `sim_param`, we first define a set of baseline values for our parameters and store them in a data frame. We will then vary the values of the parameters one after the other. We thus create vectors containing the different values of the parameters we want to test.

```{r}
sim_param_base <- tibble(
  n_days_study = 500,
  p_treat = 0.5,
  percent_effect_size = 0.5, 
  formula = "deaths_na_causes ~ treated + temperature + I(temperature^2) | city + month + year + day_of_week"
)

vect_n_days_study <- c(100, 250, 500, 750, 1000)
vect_p_treat <- c(0.1, 0.5)
vect_percent_effect_size <- c(0.1, 0.5, 1)
vect_formula <- c(
  "deaths_na_causes ~ treated", 
  "deaths_na_causes ~ treated | city",
  "deaths_na_causes ~ treated | city + month + year + day_of_week",
  "deaths_na_causes ~ treated + temperature + I(temperature^2) | city + month + year + day_of_week"
)

vect_of_vect_param <- c("vect_n_days_study", "vect_p_treat", "vect_percent_effect_size", "vect_formula")
```

We then want to create the actual table, varying parameters one after the other. To do so, we create a simple function `add_values_param`

```{r}
add_values_param <- function(df, vect_param) {
  param_name <- str_remove(vect_param, "vect_")
  
  tib_param <- tibble(get(vect_param))
  names(tib_param) <- param_name
  
  df %>% 
    full_join(tib_param, by = param_name) %>% 
    fill(everything())
}

sim_param_unique <- 
  map_dfr(
    vect_of_vect_param, 
    add_values_param, 
    df = sim_param_base
  ) %>% 
  distinct() 
```

We want to compute our simulations for this set of parameters for every design. Note that, in order to identify the effect of interest, we need to consider different types of regressions, depending on the identification strategy. 

Then, for each set of parameters we want to run many iterations of the simulation, `n_iter`. We thus modify `sim_param` so that each set of parameter appears `n_iter` times. It enable us to loop directly on `sim_param`.

```{r}
vect_treatment_type <- c("RCT", "ITS", "RDD_pm10", "DID")

sim_param <- sim_param_unique %>% 
  crossing(vect_treatment_type) %>% 
  rename(treatment_type = vect_treatment_type) %>% 
  mutate(
    formula = case_when(
      treatment_type == "DID" ~ str_replace_all(formula, "treated", "treated + post + city_treated"), 
      treatment_type == "ITS" ~ str_replace_all(formula, "treated", "treated + t + t_post"), 
      str_starts(treatment_type, "RDD") ~ str_replace_all(formula, "treated", paste("treated + ", str_remove(treatment_type, "RDD_"))), 
      TRUE ~ formula
    )
  ) %>% 
  crossing(sim_id = 1:n_iter) %>% 
  select(-sim_id) 

write_csv(sim_param, "../Outputs/sim_param.csv")
```

### Actually the simulation

We can then run the simulations for each set of parameter, using a `pmap_dfr` function.

```{r eval=FALSE}
simulations <- future_pmap_dfr(
  sim_param, 
  compute_simulation, 
  data = total_data,
  .options = furrr_options(seed = TRUE)
) 

all_simulations <- sim_param %>% cbind(simulations)

saveRDS(all_simulations, "../Outputs/data_simulations.RDS")
```

### Summarising the results

We then summarize our results, computing power, type M and so on for each set of parameters.

Once we have estimates and p-values for each iteration and each set of parameters, we will be able to compute the statistics of interest (power, type M error, etc) for each set of parameters. The function `summarise_simulations` does just that. Note that it takes as input a data frame produced with `compute_simulation` (or a mapped version of this function).

```{r eval=FALSE}
summarise_simulations <- function(data) {
  
  data %>% 
    group_by(formula, treatment_type, n_days_study, p_treat, percent_effect_size) %>%
    summarise(
      power = mean(p_value <= 0.05, na.rm = TRUE)*100, 
      bias = mean(abs((estimate - true_effect)/true_effect), na.rm = TRUE),
      average_p_value = mean(p_value, na.rm = TRUE),
      average_n_obs = mean(n_obs, na.rm = TRUE),
      type_m = mean(ifelse(p_value < 0.05, abs(estimate)/true_effect, NA), na.rm = TRUE),
      type_s = sum(ifelse(p_value < 0.05, sign(estimate) != sign(true_effect), NA), na.rm = TRUE)/n()*100,
      .groups	= "drop"
    ) %>% 
    ungroup()
} 
```

We then run this function.

```{r eval=FALSE}
summary_simulations <- summarise_simulations(all_simulations)

saveRDS(summary_simulations, "../Outputs/summary_simulations.RDS")
```








