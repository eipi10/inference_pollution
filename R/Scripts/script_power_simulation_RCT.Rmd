---
title: "Power Simulation Exercise: RCT"
author:
  - name: Vincent Bagilet 
    url: https://www.sipa.columbia.edu/experience-sipa/sipa-profiles/vincent-bagilet
    affiliation: Columbia University
    affiliation_url: https://www.columbia.edu/
  - name: Léo Zabrocki 
    url: https://www.parisschoolofeconomics.eu/en/
    affiliation: Paris School of Economics
    affiliation_url: https://www.parisschoolofeconomics.eu/en/
date: "`r Sys.Date()`"
output: distill::distill_article
---

<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE, results='hide', warning=FALSE}
library(knitr)
opts_chunk$set(fig.path = "images/",
               cache.path = "cache/",
               cache = FALSE,
               echo = FALSE, #set to false to hide code
               message = FALSE,
               warning = FALSE,
               out.width = "85%",
               dpi = 200,
               fig.align = "center")  
```  

# Purpose of the document

In this document, we carry out a simulation exercise to evaluate the performance of randomized control trials (RCTs) in measuring the short-term effects of air pollution on health. 

# Description of the analysis

## Data

We use data from 18 cities in France over the 2013-2018 period. The data set contains records of hospital admissions and deaths, mean concentration data for various air pollutants, a bunch of weather variables and calendar control variables (such as school holidays for instance). All variables are at the daily and city level. There is therefore a unique observation per date and per city in the data set.

## Background on RCTs for air pollution analyses

Here, we consider interventions leading to changes in air pollution levels on some random days. Examples of such interventions include transportation strikes or for instance. Of course, dates are often not defined as random and are likely to be correlated with unobserved variable. In the present setting, we first consider the golden standard case in which these days are defined at random. Then, we consider deviations from this golden standard.

The overall idea of the RCT is to compare the average number of deaths or hospital admissions on days with treatment to days with no treatment.


## Analysis

### Overall setting

To sum up the analysis, the aim is to measure the performance of RCTs in recovering the true effect of the treatment and to analyze the characteristics of the estimates. For simplicity, consider the daily number of death as the output variable of interest for now. To do so, we proceed as follows:

1. We define the length of the study period, *ie* the number of observations, and draw a study period randomly.
1. We define the proportion of treated days, $p_{treat}$.
1. We define the true effect size, $\beta_0$, representing the percentage change in the number of deaths in response to the treatment.
1. We define the treated days, *ie* we draw $n_{obs} \times p_{treat}$ treated days. 
1. We create fake death counts, accounting for the "true" effect of the treatment:  
$h_{ct}^{fake} = (1 + \beta_0 T_{ct}) h_{ct}$ where $h_{ct}$ represents the daily number of deaths or emergency admissions, for a given city $c$ at time $t$, $T_{ct}$ the treatment variable which is equal to 1 if the city $c$ is treated at time $t$ and zero otherwise. 
1. We estimate our model and retrieve $\hat{\beta}$ and the associated p-value.
1. We run the steps 4 to 6 $n_{iter}$ times and compare our estimated effects $\hat{\beta}$ to the true effect $\beta_0$. We compute the average bias, type M, type S and power.

In the potential outcome framework, we have $Y_{ct}(0)$, the number of deaths if a city $c$ is not treated at time $t$ equal to $h_{ct}$ and $Y_{ct}(1)$, the number of deaths if this city is treated, equal to $(1 + \beta_0 )h_{ct}$. We build our setting, so that we can "observe" both outcomes. The estimation is however performed on the fake observed data $h^{fake}$ and we have
$h^{fake} = Y(0) × (1-T) + Y(1) × T$. 

### Varying "parameters"

Note that there are several parameters we can vary in order to evaluate the performance of such RCTs: the number of observations, the proportion of treated days, the true effect size and the treatment allocation. In order to limit the number of simulations and for clarity, we only modify one parameter at the time, keeping the others constant. We consider the following values for these parameters:

- Number of observations: 1000, 2000 **because** ...
- Proportion of treated days: 0.1, 0.5, etc. The proportion of days treated matters since, while the number of observations can be large, the number of treated days may remain very small (*eg* the number of strikes). We choose these values **because** ...
- Effect size: 0.05%, 0.1% , 0.5% and 1% **because** ...
- The definition of treated days, *ie* the drawing processes: drawn at random, correlated with covariates, autocorrelated, etc (to do that, we can use the code we wrote to create missing data).
- The estimation model

# Actual implementation

In this section, we follow the steps described in the section "analysis" and carry out our analysis. We basically define a function for each step.

## Loading and Formatting Data

We load the packages and the data and wrangle it into a format well suited for this analysis.

```{r, echo=TRUE, message = FALSE, warning = FALSE}
library(here) # for files paths organization
library(tidyverse) # for data manipulation and visualisation
library(modelr) # modeling within the tidyverse
library(retrodesign) # formulas for type-m and type-s errors
library(knitr) # for tables
library(broom)

source(here::here("R", "Scripts", "script_custom_ggplot_theme.R"))

pollution_data <- readRDS(here::here("R", "Outputs", "data_daily_imputed.rds")) %>% 
  ungroup() %>% 
  mutate(
    city = tolower(city),
    city = str_remove_all(city, "[\\s-]")
  )
emergency_data <- readRDS(here::here("R", "Outputs", "emergency_data.rds"))
mortality_data <- readRDS(here::here("R", "Outputs", "mortality_data.rds"))

total_data <- pollution_data %>% 
  left_join(emergency_data, by = c("city", "date")) %>% 
  left_join(mortality_data, by = c("city", "date")) %>% 
  ungroup()

no_pollutant_data <- total_data %>% 
  select(-(no2:pm2.5)) %>% 
```

## Function definitions

### Drawing the study period

First, we create a function to randomly draw a study period of a given length. For simplicity, we choose to have the same study period for each city. This also seems realistic; a study focusing on several cities would probably consider a unique study period. Note that to do so, we need to nest the data before running the function. 

This function randomly selects a starting date for the study, early enough so that the study can actually last the number of days chosen, and returns a boolean vector indicating whether each date is in the study or not.

```{r}
draw_study_period <- function(dates, n_days_study = 1200) {
  
  max_date_allowed <- dates %>% 
    ymd() %>% 
    unique() %>% 
    which.max() %>% 
    sum(-n_days_study)
  
  begin_study <- sample(1:max_date_allowed, 1)
  
  study_period <- c(
    rep(FALSE, max_date_allowed - 1), 
    rep(TRUE, n_days_study), 
    rep(FALSE, length(dates) - n_days_study - max_date_allowed + 1)
  )
}
```

### Defining the treatment

Then, we create a function to draw the treatment. 

```{r}
draw_treated_days <- function(dates, p_treat = 0.5, treatment_type = "random") {
  
  if(treatment_type == "random") {
    treated <- rbernoulli(length(dates), p_treat)
  }
}
```

### Creating a fake output

We then create our fake output

```{r}
create_fake_output <- function(output_var, percent_effect_size = 0.5) {
  fake_output <- output_var*(1 + percent_effect_size/100)
} 
```

### Estimate the model

We can then estimate our model and retrieve the point estimate and p-value.

```{r}
estimate_model <- function(df, formula) {
  est_results <- df %>% 
    lm(data = ., formula = formula) %>% 
    tidy(., conf.int = TRUE) 
  
  est_results %>% 
    filter(term == "treatedTRUE") %>% 
    select(estimate, p.value)
} 
```

### Computing simulations

We also need a function to compute the simulations.

```{r}
compute_one_simulation <- function(df, n_days_study = 1200, p_treat = 0.5, treatment_type = "random", output_var, percent_effect_size = 0.5, formula) {
  
  df %>% 
    nest(cols = c(everything(), -date))  %>%
    mutate(study_period = draw_study_period(date, n_days_study)) %>% 
    filter(study_period) %>%
    select(-study_period) %>%
    mutate(treated = draw_treated_days("date", p_treat, treatment_type)) %>% 
    unnest() %>%
    mutate(fake_output = create_fake_output(output_var, 1)) 
  #   estimate_model(formula = "fake_output ~ treated + rainfall_height")
} 

compute_simulations(total_data, n_days_study = 2000, p_treat = 0.1, treatment_type = "random", output_var = deaths_all_causes, percent_effect_size = 1, formula)
````

```{r}
dat <- total_data %>% 
  nest(cols = c(everything(), -date)) %>% 
  mutate(study_period = draw_study_period(date, 2000)) %>% 
  filter(study_period) %>% 
  select(-study_period) %>% 
  mutate(treated = draw_treated_days(date, 0.1, "random")) %>% 
  unnest() %>% 
  mutate(fake_death = create_fake_output(deaths_all_causes, 1)) 

dat %>% 
  estimate_model(formula = "fake_death ~ treated + rainfall_height")
```

<!-- ## Estimation of the model -->

<!-- In this section we: -->

<!-- - We estimate the "true" model $h_{ct} = \alpha + \beta p_{ct} + \boldsymbol{W_{ct}'\delta} +  \boldsymbol{C_{ct}'\gamma} + \epsilon_{ct}$ -->
<!-- - We store estimates of the parameters $\alpha_0, \beta_0, \delta_0, \gamma_0$ and the mean and variance of the residuals $\epsilon_{ct}$ -->

<!-- ### Definition of the treatment -->

<!-- Here we define: -->
<!-- - $n_e$ Effect sizes -->
<!-- - $n_{obs}$ Number of observations -->
<!-- - $n_T$ different treatments, *ie* one new column in the data set for each treatment, giving the new value of pollution -->

<!-- ### Creating fake health -->

<!-- - We create the 1000 fake hospital admission and death time series -->

<!-- ### Model estimation -->

<!-- - For each time series and each treatment, we estimate our model. We thus retrieve $1000 \times n_T$ estimates -->
<!-- - For the dummy treatment and a complex one, we also vary effect size. We get $2 \times 1000 \times n_e$ estimates -->
<!-- - For the dummy treatment and a complex one, we also vary effect size. We get $2 \times 1000 \times n_e$ estimates -->
<!-- - Then, for all these estimates, we compute different measures: bias, power, rate of type I, type M and type S error, signal to noise ratio, etc. -->

<!-- ### Summary of the performance of ITS -->

<!-- The objective of this analysis is to compare the performance of different estimation methods. We therefore need a systematic way to compare them. In this section, we create the summary tables for ITS that will enable us to compare its performance to the other methods. -->

<!-- We load the packages and the data: -->

<!-- ```{r, echo=TRUE, message = FALSE, warning = FALSE} -->
<!-- library(here) # for files paths organization -->
<!-- library(tidyverse) # for data manipulation and visualisation -->
<!-- library(modelr) # modeling within the tidyverse -->
<!-- library(retrodesign) # formulas for type-m and type-s errors -->
<!-- library(knitr) # for tables -->

<!-- source(here::here("R", "Scripts", "script_custom_ggplot_theme.R")) -->

<!-- data <- readRDS(here::here("R", "Inputs", "data_marseille_daily_2008_2018.rds")) -->
<!-- ``` -->

<!-- Then, we format the data, adding relevant variables. -->

<!-- ```{r, echo=TRUE, message = FALSE, warning = FALSE} -->
<!-- data_formated <- data %>% -->
<!--   mutate_at(vars(year, holidays_dummy, bank_day_dummy), ~ as.factor(.))  %>% -->
<!--   filter(!(year %in% c("2008", "2009"))) %>% #emergency admissions data available from 2010  -->
<!--   mutate(wind_direction_categories = cut(wind_direction, breaks = seq(0, 360, by  = 90), include.lowest = TRUE) %>% -->
<!--   recode(., "[0,90]" = "North-East", "(90,180]" = "South-East", "(180,270]" = "South-West", "(270,360]" = "North-West")) %>% -->
<!--   mutate( -->
<!--     wind_speed_lag_1 = lag(wind_speed), -->
<!--     wind_direction_categories_lag_1 = lag(wind_direction_categories), -->
<!--     rainfall_dummy = ifelse(rainfall_height>0, "True", "False") -->
<!--   ) %>% -->
<!--   mutate_at(vars(mean_no2_agregate, mean_o3_l, mean_pm10_agregate, mean_pm25_l, temperature_average, humidity_average), list("01" = ~ zoo::rollmean(., k = 2, align = "right", fill = NA))) %>% -->
<!--   mutate_at(vars(mean_no2_agregate_01:humidity_average_01), ~ scale(.)) %>% -->
<!--   mutate(emergency_cv_r = log(emergency_cv_r)) %>% -->
<!--   select(date, emergency_cv_r, mean_no2_agregate, temperature_average_01, humidity_average_01, rainfall_dummy, wind_speed, wind_speed_lag_1, wind_direction_categories, wind_direction_categories_lag_1, weekday, holidays_dummy, bank_day_dummy, month, year) -->
<!-- ```       -->


<!-- # Simulations -->

<!-- ### Preparing the simulations -->

<!-- We first want to have an idea of the effect of `mean_no2_agregate` on `emergency_cv_r` in our data: -->

<!-- ```{r, echo=TRUE, message = FALSE, warning = FALSE} -->
<!-- fitted_model_real_data <- lm(emergency_cv_r ~ mean_no2_agregate +  -->
<!--               temperature_average_01 + I(temperature_average_01^2) + -->
<!--               humidity_average_01 + -->
<!--               rainfall_dummy + -->
<!--               wind_speed + wind_speed_lag_1 +  -->
<!--               wind_direction_categories + wind_direction_categories_lag_1 + -->
<!--               weekday + holidays_dummy + bank_day_dummy + month*year, data = data_formated) -->

<!-- fitted_model_real_data %>% -->
<!--   broom::tidy(., conf.int = TRUE) %>% -->
<!--   filter(term == "mean_no2_agregate") -->
<!-- ```       -->

<!-- We see that a one standard deviation in `mean_no2_agregate` lead to 0.05% (95% CI: [-0.035; 0.139]) increase in `emergency_cv_r`. -->

<!-- Using our data and this model, we can simulate fake-data for different effect sizes of `mean_no2_agregate` on -->
<!-- `emergency_cv_r`. We first create a nested tibble where store our data, variables recording the effect sizes (effect sizes = 0.05%, 0.1% , 0.5% and 1%) and the sample size (N = 1068, 1780, 2492, 3650) and the fit of the true model. -->

<!-- ```{r, echo=TRUE, message = FALSE, warning = FALSE} -->
<!-- data_simulations <- data %>%  -->
<!--   nest(data = everything()) %>% -->
<!--   crossing(effect_size = c(0.0005, 0.001, 0.005, 0.01)) %>% -->
<!--   crossing(sample_size = c(1068, 1780, 2492, 3650)) %>% -->
<!--   mutate(true_model = map(data, ~ lm(emergency_cv_r ~ mean_no2_agregate +  -->
<!--                                        temperature_average_01 + I(temperature_average_01^2) + -->
<!--                                        humidity_average_01 + -->
<!--                                        rainfall_dummy + -->
<!--                                        wind_speed + wind_speed_lag_1 +  -->
<!--                                        wind_direction_categories + wind_direction_categories_lag_1 + -->
<!--                                        weekday + holidays_dummy + bank_day_dummy + month*year, data = .))) -->
<!-- ```       -->

<!-- Once we have fitted the true model on our data, we need to modifiy the effect size of `mean_no2_agregate` in order to create new fake `emergency_cv_r` observations: -->

<!-- ```{r, echo=TRUE, message = FALSE, warning = FALSE} -->
<!-- function_model_effect_size <- function(model, effect_size){ -->
<!--   model$coefficients[2] <- effect_size -->
<!--   return(model) -->
<!-- }  -->

<!-- data_simulations <- data_simulations %>% -->
<!--   mutate(true_model = map2(true_model, effect_size, ~ function_model_effect_size(.x, .y))) -->
<!-- ```         -->

<!-- We finally need to retrieve the mean and the standard deviation of residuals found for the `fitted_model_real_data` to add some noise in our simulations: -->

<!-- ```{r, echo=TRUE, message = FALSE, warning = FALSE} -->
<!-- # get the distribution of residuals -->
<!-- mean_residuals <- mean(residuals(fitted_model_real_data)) -->
<!-- sd_residuals <- sd(residuals(fitted_model_real_data)) -->
<!-- ```       -->

<!-- ### Function to create fake-data and run the model -->

<!-- We create a function to create fake-data, run on them the model for which know the true effect size and retrieve the estimate and p-value for `mean_no2_agregate`. The function takes three arguments:the data, a sample size, and a model: -->

<!-- ```{r, eval = FALSE, message = FALSE, warning = FALSE} -->
<!-- function_power_simulation <- function(data, sample_size, true_model){ -->
<!-- simulation_results <- data %>% -->
<!--   sample_n(., sample_size, replace = TRUE) %>% -->
<!--   add_predictions(true_model, var = "predicted_emergency_cv_r") %>% -->
<!--   mutate(predicted_emergency_cv_r = predicted_emergency_cv_r + rnorm(nrow(.), mean_residuals, sd_residuals)) %>% -->
<!--   lm(predicted_emergency_cv_r ~ mean_no2_agregate +  -->
<!--        temperature_average_01 + I(temperature_average_01^2) + -->
<!--        humidity_average_01 + -->
<!--        rainfall_dummy + -->
<!--        wind_speed + wind_speed_lag_1 +  -->
<!--        wind_direction_categories + wind_direction_categories_lag_1 + -->
<!--        weekday + holidays_dummy + bank_day_dummy + month*year, data = .) %>% -->
<!--   broom::tidy() %>% -->
<!--   filter(term == "mean_no2_agregate") %>% -->
<!--   select(estimate, p.value) -->

<!--   return(simulation_results) -->
<!-- } -->
<!-- ```       -->

<!-- ### Running and Cleaning the Simulations -->

<!-- We run the simulations: -->

<!-- ```{r, eval = FALSE, message = FALSE, warning = FALSE} -->
<!-- data_simulations <- data_simulations %>% -->
<!--   crossing(id_sim = seq(1:1000)) %>% -->
<!--   mutate(simulation_results = pmap(list(data, sample_size, true_model), function_power_simulation)) -->
<!-- ```  -->

<!-- We compute the power, type m and s errors: -->

<!-- ```{r, eval = FALSE, message = FALSE, warning = FALSE} -->
<!-- data_simulation_results <- data_simulations %>% -->
<!--   select(-data, - true_model) %>% -->
<!--   unnest(simulation_results) -->

<!-- data_simulation_results_power <- data_simulation_results %>% -->
<!--   group_by(sample_size, effect_size) %>% -->
<!--   summarise(power = mean(p.value<= 0.05)*100) -->

<!-- data_simulation_results_m_error <- data_simulation_results %>% -->
<!--   group_by(sample_size, effect_size) %>% -->
<!--   filter(p.value <= 0.05) %>% -->
<!--   summarise(type_m_error = mean(abs(estimate)/effect_size)) -->

<!-- data_simulation_results_s_error <- data_simulation_results %>% -->
<!--   group_by(sample_size, effect_size) %>% -->
<!--   filter(p.value <= 0.05) %>% -->
<!--   summarise(type_s_error = (sum(estimate<0)/n())*100) -->

<!-- # join the figures together -->
<!-- data_simulation_results_all <- left_join(data_simulation_results_power, data_simulation_results_m_error, by = c("sample_size", "effect_size")) %>% -->
<!--   left_join(., data_simulation_results_s_error, by = c("sample_size", "effect_size")) -->
<!-- ```  -->


<!-- ### Simulation Results -->

<!-- We plot below the simulations results: -->

<!-- ```{r, echo = FALSE, message = FALSE, warning = FALSE, fig.width=20, fig.height=8, fig.fullwidth=TRUE, dev = "CairoPNG"} -->
<!-- # load simulation results data -->
<!-- data_simulation_results <- readRDS(here::here("1.data", "1.standard_model", "simulation_results.RDS")) -->

<!-- # make the graph -->
<!-- graph <- data_simulation_results %>% -->
<!--   mutate_at(vars(sample_size, effect_size), ~ as.factor(.)) %>% -->
<!--   mutate(effect_size = case_when(effect_size == "5e-04" ~ "+0.05%", -->
<!--                                  effect_size == "0.001" ~ "+0.1%", -->
<!--                                  effect_size == "0.005" ~ "+0.5%", -->
<!--                                  effect_size == "0.01" ~ "+1%")) %>% -->
<!--   rename("Power (%)" = power, "Type M Error (Bias)" = type_m_error, "Type S Error (%)" = type_s_error) %>% -->
<!--   pivot_longer(cols= c(`Power (%)`:`Type S Error (%)`), names_to = "variable", values_to = "value") %>% -->
<!--   ggplot(., aes(x = sample_size, y = value, group = effect_size, color = effect_size)) + -->
<!--   geom_line(linetype = "dashed") + -->
<!--   geom_point(size = 4) + -->
<!--   scale_color_manual(values=c("#f2cc8f", "#3d405b", "#81b29a", "#e07a5f")) + -->
<!--   facet_wrap(~ variable, scales = "free", nrow = 1) + -->
<!--   xlab("Sample Size") + ylab("Value") + -->
<!--   ggtitle("Power Simulations Results", subtitle = "The effect of a one standard deviation increase in NO2 on Emergency Admissions.") + -->
<!--   labs(color = "Effect Size:") + -->
<!--   custom_theme + -->
<!--   theme(legend.position = "top", legend.justification = "left", legend.direction = "horizontal") -->

<!-- # print graph -->
<!-- graph -->

<!-- # save graph -->
<!-- ggsave(graph, filename = here::here("3.outputs", "1.figures", "graph.pdf"),  -->
<!--        width = 45, height = 20, units = "cm", device = cairo_pdf) -->
<!-- ```  -->

<!-- We can compare our results with those of `retrodesign` package: -->

<!-- ```{r, eval = TRUE, message = FALSE, warning = FALSE} -->
<!-- tibble(effect_size = c(0.0005, 0.001, 0.005, 0.01), standard_error = c(rep(0.00045, 4))) %>% -->
<!--   mutate(power = map2(effect_size, standard_error, ~ retro_design(.x, .y)$power*100), -->
<!--          type_s = map2(effect_size, standard_error, ~ retro_design(.x, .y)$typeS*100), -->
<!--          type_m = map2(effect_size, standard_error, ~ retro_design(.x, .y)$typeM)) %>% -->
<!--   unnest(cols = c(power, type_s, type_m)) %>% -->
<!--   mutate_at(vars(power:type_m), ~ round(., 1)) %>% -->
<!--   mutate(effect_size = case_when(effect_size == "5e-04" ~ "+0.05%", -->
<!--                                  effect_size == "0.001" ~ "+0.1%", -->
<!--                                  effect_size == "0.005" ~ "+0.5%", -->
<!--                                  effect_size == "0.01" ~ "+1%")) %>% -->
<!--   kable() -->
<!-- ```  -->









