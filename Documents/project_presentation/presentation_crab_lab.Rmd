---
title: "Analysis of studies on the short term health effects of air pollution"
author: "Vincent Bagilet - Leo Zabrocki"
date: "November 30, 2020"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      countIncrementalSlides: no
      highlightLines: yes
      highlightStyle: github
  github_document: default
  ioslides_presentation:
    highlight: pygments
  html_notebook:
    highlight: pygments
    theme: simplex
    toc: yes
  slidy_presentation:
    highlight: pygments
  beamer_presentation:
    highlight: pygments
    theme: VB_Beamer
  html_document:
    highlight: pygments
    theme: simplex
  pdf_document:
    includes:
      in_header: VB_markdown.sty
    keep_tex: yes
subtitle: "Crab lab presentation"
---

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
mono_light(
  base_color = "#1B2754",
  header_font_google = google_font("Lato", "400"),
  text_font_google   = google_font("Raleway", "300", "300i"),
  header_font_weight = "bold",
  text_bold_color = "#B67F10",
  text_font_size = "24px",
  header_h1_font_size = "45px",
  header_h2_font_size = "35px",
  header_h3_font_size = "25px"
)
```

# Genesis of the project

--

```{r echo=FALSE, out.width= 500, fig.align="center"} 
knitr::include_graphics("images/book.gif")
```

--

```{r echo=FALSE, out.width= 800, fig.align="center"} 
knitr::include_graphics("images/genesis_graph.png")
```

???

- While LÃ©o was working on several projects on short term health effects of air pollution some questions arose:

  - How do different methods compare in terms of estimation of these effects?
  
  - How should we handle missing data in such studies?
  
- Starting from there, it led to additional questions

  - Are missing data an actual problem?
  
  - What is the usual power in such studies? Does it varies with estimation methods?

- Very methodological project: we are interested in learning a lot of methods

---

# Main questions and motivation

- What is the usual **power** in studies of short-term health effects of air pollution?
  
- How do **different identification strategies** perform to estimate these effects?
  
- What is the impact of **missing data** on these estimates? 

```{r echo=FALSE, out.width= 350, fig.align="center"} 
knitr::include_graphics("images/pollution_paris.jpg")
```
  
- I skip the motivation overall section for the sake of time

???

- The questions we will focus on will also depend on our results: it might be the case that missing data is not a problem for instance. In this case we would not focus on this

- You know why understanding the health effects of air pollution is an important question. However, I will discuss why each subquestion matters

- In this presentation, I tackle each question somehow separately

---

# Usual power in air pollution studies

## Definitions

- **Power**: probability of finding an effect when there is actually one

- Power can be low when effects are small and/or variance of the estimates is large (*eg* small sample size)

- Type M and type S errors:

```{r echo=FALSE, out.width= 250, fig.align="center"} 
knitr::include_graphics("images/typeMS.png")
```

---

## Motivation

- Ioannidis et al (2017) showed that studies in economics are massively under-powered: median statistical power of 18%

- Is there a similar issue in studies of health effects of air pollution?

- Health effects of air pollution are often tiny, making them difficult to detect

- Low power is associated with high rates of type M and S error

---

## Method

- Follow Ioannidis and retrieve point estimates and s.e. of estimates

- Compute power, type M and type S errors using the package `retrodesign`

- Literature review of causal studies: yield a set of $\sim$ 30 studies

- Systematic literature review for other studies: for now, we retrieved about 1000 estimates


## Results

- 

- 

---

# Performance of different methods

## Motivation

- Epidemiologists often use very simple models, with small sample size: is it enough to recover the true effects? 

- Are more fancy techniques an overkill?

- Some methods can perform better than other in some contexts but less well in others

- Want to compare: Poisson generalized additive model, IV, DiD, event study, RD

???

- Keep in mind that this is also a way for us to play around with many estimation strategies and to build some methodological knowledge

---

## Method

- For the sake of the example, let's focus on a simple Poisson generalized additive model:

$$h_{ct} = \alpha + \beta_{c}p_{ct} + \boldsymbol{W_{ct}'\delta} +  \boldsymbol{C_{ct}'\gamma} + \epsilon_{ct}$$
- Actual data and fake data

- We est

---

# Impact of missing values

## Motivation

- Air pollution data sets always display missing observations: not always clear how to handle them

- Missing data can create bias and decrease precision, especially if large amounts of data are missing

- We will be able to motivate it better (or dismotivate it) when we have more results






