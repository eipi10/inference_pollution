{
  "articles": [
    {
      "path": "index.html",
      "title": "Inference Design in Studies of Acute Health Effects of Air Pollution",
      "description": "This website gathers code and additional material for the paper [Inference Design in Studies of Acute Health Effects of Air Pollution](draft_2021_06_11.pdf) by Vincent Bagilet and Léo Zabrocki.\n",
      "author": [],
      "contents": "\nAbstract\nWe explore statistical power issues of various empirical strategies implemented to estimate the short-term health effect of air pollution. Through an extensive literature review, we retrieve the estimates and standard errors of nearly all studies published on this topic, which rely both on standard outcomes regressions and causal inference methods. We find that a non-negligible share of studies may suffer from low power issues and could thereby exaggerate effect sizes. The analysis of published results highlights potential shortcomings of the literature but does not enable to precisely identify drivers of theses issues. We therefore run realistic simulations to investigate how statistical power varies with the treatment effect size, the number of observations, the proportion of treated units as well as the distribution of the outcome. Instrumental variable estimates, when statistically significant, are more likely to overestimate true effect sizes than naive estimates. Researchers should also pay attention to the number of treated units and the average count of health outcomes as they are important drivers of statistical power and may lead to greatly overestimated true effect sizes.\n\n\n\n",
      "last_modified": "2021-06-23T13:05:19+02:00"
    },
    {
      "path": "notes_methodology.html",
      "title": "Power Simulation: Theory and Intuition",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://www.sipa.columbia.edu/experience-sipa/sipa-profiles/vincent-bagilet"
        },
        {
          "name": "Léo Zabrocki",
          "url": "https://www.parisschoolofeconomics.eu/en/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nPurpose of the document\nData\nBackground on selected quasi-experimentsTreatment on “random” days\nAir pollution alert\nNo quasi experiment\n\nIdentification methodReduced form\nRegression Discontinuity Design\nInstrumental variable\nLinear model\n\nAnalysisOverall setting\nVarying “parameters”\n\n\n\nbody {\ntext-align: justify}\nPurpose of the document\nIn this document, we discuss the “theory” behind our simulations and the overall implementation for these simulations.\nData\nWe use data from 68 cities in the US over the 1987-1997 period. This data is a subset of the US National Morbidity, Mortality, and Air Pollution Study (NMMAPS). The data set contains records of deaths, mean concentration data for carbon monoxide (CO), temperature data and calendar control variables (such as school holidays for instance). All variables are at the daily and city level. There is therefore a unique observation per date and per city in the data set.\nBackground on selected quasi-experiments\nWe focus on quasi experiments for which treatment is binary and homogeneous, both in time and across individuals. Treatment is also not correlated with covariates (apart for air pollution alerts in which case treatment is of course correlated with the pollutant level).\nTreatment on “random” days\nHere, we consider interventions leading to changes in air pollution levels on some random days. Examples of such interventions include transportation strikes. Of course, dates are often not defined as random and are likely to be correlated with unobserved variables. In the present setting, we first consider the golden standard case in which these days are actually defined at random. One can think of this case as a Randomized Control Trial: it represents what would happen if an experimenter could implement a treatment increasing pollution on random days.\nAir pollution alert\nHere, we consider interventions that affect exposure to air pollution when air pollution levels reach a given threshold. Examples of such interventions include air pollution alerts: when pollution reaches a certain level, alerts are released, inviting people to reduce their exposure.\nNo quasi experiment\nWe finally consider a case for which there is no quasi experiment. One can consider that in this case all units are treated. To measure the effect of air pollution on health in this case, we will use methods from the epidemiology literature, as discussed in the next section.\nIdentification method\nIn order to estimate the parameters of interest, we use several identification methods. We associate each identification method with a given quasi-experiment.\nReduced form\nWe use a reduced form model to estimate the effect of a treatment on random days. The overall idea of the reduced form approach is to only compare the average number of deaths or hospital admissions in cities with treatment to cities with no treatment on the same day, controlling for differences across cities. In such approach, we do not model the impact of the treatement on air pollution.\nThis identification method enables to estimate the Average Treatment Effect (ATE), ie a difference in mean between the treated and the control group (\\(\\mathbb{E}[Y_{1i} - Y_{0i}]\\)). To do so, we use the following type of model:\n\\[Y_{ct} = \\alpha + \\beta T_{ct} + \\epsilon_{ct}\\] where, as in the whole document, \\(Y_{ct}\\) is the health outcome of interest (for instance mortality), in a city \\(c\\), at date \\(t\\). The parameter of interest is \\(\\beta\\) (we use this notation for all models) and \\(T_{ct}\\) is a dummy equal to 1 if the city \\(c\\) is treated at time \\(t\\) and 0 otherwise.\nThe identification assumption here is that the the potential outcomes are independent of the treatment (independence assumption). In our simulations, this is verified as the treatment is allocated randomly.\nRegression Discontinuity Design\nWe use a Regression Discontinuity Design (RDD or RD) to estimate the effect of an air pollution alert type of intervention. The overall idea of the RD is to compare days just below the threshold to days just above the threshold (where exposure and health impacts are thus lower). The key identification assumption is that days just below and just above the threshold are comparable. Thus, no confounders should vary discontinuously at the threshold (local independence, \\((Y_{0i}, Y_{1i}) \\perp T_i|Z_i\\), for \\(Z_i \\in [c-a, c+a]\\) ) and the treatment should vary at threshold (relevance, \\(T_i = \\mathbb{1} \\{Z_i \\geq c\\}\\)). The way we model this, both these assumptions are verified. However, for large bandwidth, observations above and below the threshold may be less comparable.\nThis identification method enables to estimate a Local Average Treatment Effect (LATE) at the cutoff, ie \\(\\mathbb{E}[Y_{1i} - Y_{0i}|Z_i = c]\\). To do so, we use the following type of model, but restricting our sample to observation just below and just above the threshold:\n\\[Y_{ct} = \\alpha + \\beta T_{ct} + \\epsilon_{ct}\\]\nInstrumental variable\nIn the previous identification methods, we tried to estimate a reduced form, ie looking at the effect of a treatment directly on mortality. We did not consider the effect of the treatment on air pollution, ie the mechanism. In this section, we instrument the effect of pollution on the outcome with an instrument/treatment. We basically model the effect of an exogeneous instrument on air pollution and use this information to retrieve a causal estimate of the short term effect of air pollution on health. Note that the class of treatments/instruments considered here can be broader than in the previous section. Yet, in these simulations, we only consider a treatment on random days, for simplicity.\nIn a first step, we only consider binary instruments such as thermal inversions and high/low wind speed for instance. This type of instruments corresponds to a large share of the instruments considered in the literature. The key assumption is that these treatments only affect the health outcome variable via their effect on air pollution. Since the treatment is drawn randomly this is verified in our simulations.\nLet’s denote \\(Z\\) this instrument. We compute a 2-Stages Least Squares (2SLS) where the first stage has the form:\n\\[Poll_{ct} = \\gamma + \\delta Z_{ct} + e_{ct}\\] and the second stage:\n\\[Y_{ct} = \\alpha + \\beta Poll_{ct} + \\epsilon_{ct}\\]\nLinear model\nFinally, we also consider simple linear models in order to measure the correlation between the health outcome of interest and air pollution, controlling for potential confounders. The identification assumptions here are the usual OLS assumptions.\nWe estimate a model of the form:\n\\[Y_{ct} = \\alpha + \\beta Poll_{ct} + \\epsilon_{ct}\\]\nAnalysis\nOverall setting\nTo sum up the analysis, the aim is to measure the inference properties of different research designs aiming at measuring the short-term effects of air pollution on health. For simplicity, consider the daily number of death as the output variable of interest for now. We proceed as follows:\n\nWe draw a study period randomly.\nWe define the treated days, ie we define a treatment variable \\(T_{ct}\\) equal to 1 if the city \\(c\\) is treated at time \\(t\\) and zero otherwise.\nWe create a fake number of deaths, modifying the observed number of deaths and adding the treatment effect.\nWe estimate our model with \\(Y_{obs}\\) as a dependent variable and retrieve \\(\\hat{\\beta}\\).\nWe run the steps 1 through 5 \\(n_{iter}\\) times.\nWe compute the type M, type S, power and other statistics of interest.\nVarying “parameters”\nWe can vary several parameters to evaluate the sensitivity of power, type M and type S to the value of these parameters: the identification method, the number of observations, the proportion of treated days, the true effect size and the model specification. In order to limit the number of simulations and for clarity, we only modify one parameter at the time, keeping others constant and equal to a baseline value. When we vary a parameter in our main simulation, we consider the following values:\nNumber of observations: we can vary both the length of the study, in days, and the number of cities but mostly keep the number of cities considered fixed. We consider 100, 500, 1000, 2000, 3000 and 4000 days. This covers a wide range of plausible study lengths. In a first set of simulations, we consider almost “ideal” baseline parameters and thus set the number of observations to 3000. We also set the number of cities to 40\nProportion of treated days: 0.01, 0.025, 0.05, 0.1, 0.25, 0.5. The proportion of days treated matters since, while the number of observations can be large, the number of treated days may remain very small (eg the number of strikes). We choose these values because …\nEffect size: 0.1%, 0.5%, 1%, 2%, 5%, 10% because …\nOutcome considered (and therefore its distribution)\nThe estimation model: we first do not include covariates, only fixed effects. We then include include different sets of covariates.\nWe consider this set of parameters for each identification method.\n\n\n\n",
      "last_modified": "2021-06-23T13:04:14+02:00"
    },
    {
      "path": "power_simulations.html",
      "title": "Power Simulation Exercise",
      "author": [
        {
          "name": "Vincent Bagilet",
          "url": "https://www.sipa.columbia.edu/experience-sipa/sipa-profiles/vincent-bagilet"
        },
        {
          "name": "Léo Zabrocki",
          "url": "https://www.parisschoolofeconomics.eu/en/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\n\nContents\nPurpose of the document\nFunction definitionsSelecting the study period\nDefining the treatment\nCreating fake output\nEstimating the model\nComputing simulations\n\nRunning the simulationsDefining baseline parameters\nEvolution with values of a given parameterDefining parameters\nRunning the simulation\nSummarising the results\n\nSmall number of observations\nDecomposing the number of observations into number of cities and days\nDecomposing the number of treated into number of observations and proportion of treated\nUsual values in the literatureRDD\nReduced form\nIV\nRunning simulations\n\n\n\n\nbody {\ntext-align: justify}\nPurpose of the document\nIn this document, we carry out a simulation exercise to evaluate the inference properties of different research designs aiming at measuring the short-term effects of air pollution on health. We consider different types of quasi experiments and for each associate one or several identification strategies.\nThis document focuses on running the simulations. The results are analyzed and discussed in another document.\nFunction definitions\nSelecting the study period\nFirst, we create a function to randomly select a study period of a given length. This function also randomly selects a given number of cities to consider. For simplicity, we choose to have the same temporal study period for each city. This also seems realistic; a study focusing on several cities would probably consider a unique study period.\nThis function randomly selects a starting date for the study, early enough so that the study can actually last the number of days chosen. It then randomly draws a given number of cities and filters out observations outside of the study period. It returns a data set with only the desired number of cities and days.\n\n\nselect_study_period <- function(data, n_days = 3000, n_cities = 68) {\n  dates <- data[[\"date\"]]\n  err_proof_n_days <- min(n_days, length(unique(dates)))\n  cities <- data[[\"city\"]]\n  err_proof_n_cities <- min(n_cities, length(unique(cities)))\n  \n  begin_study <- sample(\n    seq.Date(\n      min(dates), \n      max(dates) - err_proof_n_days, \n      \"day\"\n    ), 1)\n  \n  dates_kept <- dplyr::between(\n    dates, \n    begin_study, \n    begin_study + err_proof_n_days\n  )\n  \n  cities_kept <- cities %in% sample(levels(cities), size = err_proof_n_cities)\n  \n  data_study <- data[(dates_kept & cities_kept),]\n  return(data_study)\n}\n\n\n\nDefining the treatment\nThen, we create a function to draw the treatment. This function adds a boolean vector to our data, stating whether each observation is in the treatment group or not. The drawing procedure depends on the quasi experiment considered (quasi_exp) and the proportion of treated observations (p_obs_treat). We consider three quasi-experiments:\nRandom days, corresponding to a random allocation of the treatment (random_days)\nAir pollution alerts (alert_... with … being the pollutant name )\nNo quasi-experiment (none)\nNote that for the alert, we will use RDD to estimate the effect of the treatment. We therefore restrict our sample to observations in a given bandwidth. We draw a threshold position from a uniform distribution from 0.2 to 0.4 in order to have enough observations in our data set. If we pick the threshold position too high up in the distribution of CO concentration, we may end up with observations very far away from the samples. For each city, we find the corresponding threshold and define a bandwidth such that p_obs_treat observations of the total sample are treated. Observations outside the bandwidth get a NA for treated. Thus, after calling this function, we need to filter out observations with a NA for treated.\n\n\ndraw_treated <- function(data, p_obs_treat = 0.5, quasi_exp = \"random_days\") {\n  \n  if (quasi_exp == \"random_days\") {\n    data[[\"treated\"]] <- rbernoulli(length(data[[\"date\"]]), p_obs_treat)\n  } else if (str_starts(quasi_exp, \"alert\")) {\n    pollutant <- str_extract(quasi_exp, \"(?<=_).+\")\n    # threshold_pos <- rbeta(1, 20, 7) \n    threshold_pos <- runif(1, 0.2, 0.4) \n    data <- data %>%\n      group_by(.data$city) %>%\n      mutate(\n        threshold = quantile(.data[[pollutant]], threshold_pos, names = FALSE),\n        bw_high = quantile(.data[[pollutant]], min(threshold_pos + p_obs_treat, 1), names = FALSE),\n        treated = ifelse(\n          .data[[pollutant]] > bw_high | .data[[pollutant]] < threshold - (bw_high - threshold), \n          NA, \n          (.data[[pollutant]] >= threshold)\n        )\n      ) %>%\n      select(-bw_high, -threshold) %>% \n      ungroup()\n  } else {\n    data[[\"treated\"]] <- TRUE\n  }\n  \n  return(data)\n}\n\n\n\nBoth to verify that everything works well and for illustration, we can make quick plots:\n\n\n\nCreating fake output\nWe then create the fake output, y_fake. The generative process depends on the identification method:\nFor binary treatments, we draw a treatment effect from a Poisson distribution with mean corresponding to the effect size desired.\nFor the OLS, we build a generative model that creates fake data based on the formula given and with an effect corresponding to the effect size desired.\nFor the IV, we use the same method as for the OLS but previously, we modified the value of pollutant concentration through the instrument. The instrument is binary and affects pollutant concentration: \\(Poll_{ct}^{fake} = Poll_{ct} + \\delta T_{ct} + e_{ct}\\), where \\(T_{ct}\\) is the treatment dummy, \\(\\delta\\) the treatment “intensity” (the iv_strength in our function) and \\(e \\sim \\mathcal{N}(0, 0.1)\\) a noise.\nWe also create a short function to detect a pollutant among independent variables of a formula. We also use this function later. In the present document we only consider CO but we made the function more general.\n\n\nfind_pollutant <- function(formula) {\n    pollutants_list <- c(\"co\", \"pm10\", \"pm2.5\", \"no\")\n    pollutant <- pollutants_list[pollutants_list %in% all.vars(formula)]\n    return(pollutant)\n}\n\ncreate_fake_output <- function(data,\n                      percent_effect_size = 0.5,\n                      id_method = \"reduced_form\", \n                      iv_strength = NA, \n                      formula) {\n  \n  fml <- Formula::as.Formula(formula)\n  dep_var <- all.vars(fml)[[1]]\n  \n  if (id_method == \"RDD\") {\n    \n    data <- data %>%\n      group_by(.data$city) %>%\n      mutate(\n        y1 = .data[[dep_var]] -\n          rpois(\n            n(),\n            mean(.data[[dep_var]], na.rm = TRUE) * percent_effect_size / 100\n          ) %>% suppressWarnings(), #warnings when is.na(dep_var) eg rpois(1, NA)\n        y_fake = .data[[\"y1\"]] * .data[[\"treated\"]] + .data[[dep_var]] * (1 - .data[[\"treated\"]])\n      ) %>%\n      ungroup()\n    \n  } else if (id_method == \"reduced_form\") {\n\n    #Just a different sign\n    data <- data %>%\n      group_by(.data$city) %>%\n      mutate(\n        y1 = .data[[dep_var]] +\n          rpois(\n            n(),\n            mean(.data[[dep_var]], na.rm = TRUE) * percent_effect_size / 100\n          ) %>% suppressWarnings(), #warnings when is.na(dep_var) eg rpois(1, NA)\n        y_fake = .data[[\"y1\"]] * .data[[\"treated\"]] + .data[[dep_var]] * (1 - .data[[\"treated\"]])\n      ) %>%\n      ungroup()\n    \n  } else if (id_method %in% c(\"OLS\", \"IV\")) {\n    pollutant <- find_pollutant(fml)\n    \n    if (id_method == \"IV\") {\n      data[[pollutant]] <- \n        data[[pollutant]] + \n        iv_strength*data[[\"treated\"]] +\n        rnorm(data[[pollutant]], 0, 0.1)\n      \n      #need to withdraw the first stage from the formula and add the pollutant\n      parts_formula <- str_split(formula, \"\\\\|\")[[1]]\n      formula_clean <- str_c(\n        parts_formula[1], \n        \"+\", str_extract(parts_formula[3], \"\\\\b.+(?=~)\"),\n        \"|\", parts_formula[2]\n      )\n    } else {\n      formula_clean <- formula\n    }\n    \n    fml <- Formula::as.Formula(formula_clean)\n    reg <- feols(data = data, fml = fml, combine.quick=FALSE)\n    reg$coefficients[[pollutant]] <- mean(data[[dep_var]])*percent_effect_size/100  \n    #to get beta as the increase in percent\n    res <- reg$residuals\n    \n    data[[\"y_fake\"]] <- predict(reg, data) + rnorm(res, mean(res), sd = sd(res))\n    # data[[\"y1\"]] <- ifelse(data[[\"y1\"]] < 0, 0, data[[\"y1\"]])\n  } \n  \n  return(data)\n} \n\n\n\nThe proportion of treated observations corresponds to the ratio of the number of orange dots and the total number of dots.\nEstimating the model\nWe can then estimate our model and retrieve the point estimate, p-value, standard error, number of observations and f-stat. The model should be specified in a three part formula as follows: y ~ x | fixed effects | endo_var ~ instrument. If one does not want to set fixed effects, a 0 should be put in the second part of the formula: y ~ x | 0 | endo_var ~ instrument.\n\n\nestimate_model <- function(data, formula) {\n  fml <- Formula::as.Formula(formula)\n  pasted_formula <- paste(str_c(fml)[[2]], str_c(fml)[[1]], str_c(fml)[[3]])\n  \n  #the param of interest varies across identification methods\n  param_of_interest <- \n    ifelse(str_count(pasted_formula, \"\\\\|\") == 2, #if IV (ie 3 parts rhs in formula)\n           str_c(\"fit\", find_pollutant(fml), sep = \"_\"), \n           ifelse(\"treated\" %in% all.vars(fml), \"treatedTRUE\", find_pollutant(fml)))\n  \n  #run the estimation\n  est_results <- feols(data = data, fml = fml, se = \"hetero\") \n  \n  #retrieve the useful info\n  nobs <- length(est_results$residuals)\n  fstat <- fitstat(est_results, type = \"ivf\")$ivf1 %>% as_vector() %>% .[[1]]\n  \n  est_results %>%\n    broom::tidy(conf.int = TRUE) %>%\n    filter(term == param_of_interest) %>%\n    rename(p_value = p.value, se = std.error) %>%\n    select(estimate, p_value, se) %>%\n    mutate(\n      n_obs = nobs,\n      f_stat = fstat\n    )\n}   \n# estimate_model(draw_treated(nmmaps_data), \"death_total ~  temperature + temperature_squared | city + month^year + weekday | co ~ treated\")\n\n\n\nComputing simulations\nBefore running all these functions together to compute one simulation, we need to compute the true effect. The different identification methods aims to identify different estimands (ATE or ATET). We therefore write a short function to compute this true effect.\n\n\ncompute_true_effect <- function(data, id_method, percent_effect_size, dep_var) {\n  \n  if (id_method %in% c(\"OLS\", \"IV\")) {\n    true_effect <- percent_effect_size/100*mean(data[[dep_var]])\n  } else {#ATE\n    true_effect <- mean(data$y1 - data$y0, na.rm = TRUE)\n  }\n  \n  return(true_effect)\n}\n\n\n\nWe can now create a function running all the previous functions together and therefore performing an iteration of the simulation, for a given set of parameters. This function returns a one row data set with estimate, p-value, number of observations and true effect size.\n\n\ncompute_simulation <- function(data,\n                               n_days = 3000,\n                               n_cities = 68, \n                               p_obs_treat = 0.5,\n                               percent_effect_size = 1,\n                               quasi_exp = \"random_days\",\n                               id_method = \"reduced_form\", \n                               iv_strength = NA,\n                               formula = \"resp_total ~ treated\",\n                               progressbar = progressor()#to have a progressbar when mapping\n                               ) {\n  \n  fml <- Formula::as.Formula(formula)\n  dep_var <- all.vars(fml)[1]\n\n  sim_data <- data %>%\n    select_study_period(n_days, n_cities) %>%\n    mutate(y0 = .data[[dep_var]]) %>%\n    draw_treated(p_obs_treat, quasi_exp) %>% \n    create_fake_output(percent_effect_size, id_method, iv_strength, formula) %>% \n    filter(!is.na(treated)) #not necessary bc dropped in lm()\n  \n  updated_fml <- str_replace(formula, dep_var, \"y_fake\")\n\n  sim_output <- sim_data %>%\n    estimate_model(formula = updated_fml) %>% \n    mutate(\n      true_effect = compute_true_effect(\n        sim_data, \n        id_method, \n        percent_effect_size, \n        dep_var\n      ),\n      n_days = n_days, \n      n_cities = n_cities,\n      p_obs_treat = p_obs_treat,\n      percent_effect_size = percent_effect_size,\n      quasi_exp = quasi_exp,\n      id_method = id_method, \n      iv_strength = iv_strength,\n      formula = formula\n    )\n  \n  progressbar() \n  return(sim_output)\n}\n\nnmmaps_data %>%\n  compute_simulation(\n    data = .,\n    formula = \"death_total ~ treated + co + temperature + temperature_squared | city + month^year + weekday\",\n    quasi_exp = \"alert_co\",\n    id_method = \"RDD\",\n    iv_strength = 0.5,\n    n_days = 1000,\n    n_cities = 10,\n    percent_effect_size = 1,\n    p_obs_treat = 0.5\n  )\n\n\n# A tibble: 1 x 14\n  estimate p_value    se n_obs f_stat true_effect n_days n_cities\n     <dbl>   <dbl> <dbl> <int> <lgl>        <dbl>  <dbl>    <dbl>\n1  -0.0250   0.916 0.236  7641 NA          -0.312   1000       10\n# … with 6 more variables: p_obs_treat <dbl>,\n#   percent_effect_size <dbl>, quasi_exp <chr>, id_method <chr>,\n#   iv_strength <dbl>, formula <chr>\n\nWe will then loop this function to get a large number of replications of each simulation for a given set of parameters. We will also vary the values of the different parameter.\nRunning the simulations\nBefore running the simulations, we need to define the set of parameters to consider.\nDefining baseline parameters\nWe will create a table displaying in each row a set of parameters we want to have a simulation for, sim_param_evol. We will then map our function compute_simulation on this table.\nTo build sim_param_evol, we first define a set of baseline values for our parameters and store them in a data frame, sim_param_base.\n\n\nsim_param_base <- tibble(\n  n_days = 2500,\n  n_cities = 40,\n  p_obs_treat = 0.5,\n  percent_effect_size = 1, \n  iv_strength = 0.5,\n  formula = \"death_total ~ treated + temperature + temperature_squared | city + month^year + weekday\"\n)\n\n# saveRDS(sim_param_base, \"R/Outputs/sim_param_base.RDS\")\n# write_csv(sim_param_base, \"R/Outputs/sim_param_base.csv\")\n\n\n\nEvolution with values of a given parameter\nDefining parameters\nIn a first set of simulation, we vary the values of the parameters one after the other. We thus create vectors containing the different values of the parameters we want to test.\n\n\nvect_n_days <- c(100, 500, 1000, 2000, 3000, 4000)\nvect_p_obs_treat <- c(0.01, 0.025, 0.05, 0.1, 0.25, 0.5)\nvect_percent_effect_size <- c(0.1, 0.5, 1, 2, 5, 10)\nvect_iv_strength <- c(0.01, 0.1, 0.2, 0.5, 0.7)\nvect_formula <- c(\n  # \"death_total ~ treated\",\n  \"resp_total ~ treated + temperature + temperature_squared | city + month^year + weekday\",\n  \"death_total ~ treated + temperature + temperature_squared | city + month^year + weekday\",\n  \"copd_age_65_75 ~ treated + temperature + temperature_squared | city + month^year + weekday\"\n)\n\n\n\nWe then want to create the actual table, varying the parameters one after the other. To do so, we create a simple function add_values_param. This function adds the values of a parameter contained in a vector. We can then loop this function on all the vectors of parameters of interest.\n\n\n#adds all values in vect_param\nadd_values_param <- function(df, vect_param) {\n  param_name <- str_remove(vect_param, \"vect_\")\n  \n  tib_param <- tibble(get(vect_param))\n  names(tib_param) <- param_name\n  \n  df %>% \n    full_join(tib_param, by = param_name) %>% \n    fill(everything(), .direction = \"downup\")\n}\n\nvect_of_vect_param <- c(\n  \"vect_n_days\", \n  \"vect_p_obs_treat\", \n  \"vect_percent_effect_size\", \n  \"vect_iv_strength\", \n  \"vect_formula\"\n)\n\nsim_param_unique <- \n  map_dfr(\n    vect_of_vect_param, \n    add_values_param, \n    df = sim_param_base\n  ) %>% \n  distinct() #bc base parameters appear twice\n\n\n\nWe want to compute our simulations for this set of parameters for every identification method so we replicate this set of parameters for each identification method (and add information about the associated quasi-experiment). Then, in order to identify the effect of interest, we need to consider different types of equations, depending on the identification method considered. For each set of parameters we want to run many iterations of the simulation so we replicate the dataset n_iter times. It will enable us to loop compute_simulation directly on sim_param_evol.\nNote that we make a bunch of small modification to have more realistic parameters. For instance, we only consider small proportions of treated observations for the RDD.\nWe wrap all this into a function, prepare_sim_param.\n\n\nprepare_sim_param <- function(df_sim_param, \n                              vect_id_methods = c(\"reduced_form\", \"RDD\", \"OLS\", \"IV\"), \n                              n_iter = 10) {\n  \n  sim_param_clean <- df_sim_param %>%\n    crossing(vect_id_methods) %>%\n    rename(id_method = vect_id_methods) %>%\n    mutate(\n      quasi_exp = case_when(\n        id_method == \"reduced_form\" ~ \"random_days\",\n        str_starts(id_method, \"RDD\") ~ \"alert_co\",\n        id_method == \"OLS\" ~ \"none\",\n        id_method == \"IV\" ~ \"random_days\",\n      )\n    ) %>% \n    mutate(\n      formula = case_when(\n        id_method == \"OLS\" ~ str_replace_all(formula, \"treated\", \"co\"),\n        id_method == \"IV\" ~ paste(\n          str_remove_all(formula, \"(\\\\+\\\\s)?\\\\btreated\\\\b(\\\\s\\\\+)?\"),\n          \"| co ~ treated\"\n          ),\n        TRUE ~ formula\n      )\n    ) %>% \n    filter(!str_detect(formula, \"~\\\\s{0,2}\\\\|\")) %>% \n    #adapting parameters\n    mutate(\n      p_obs_treat = ifelse(id_method == \"RDD\", p_obs_treat/5, p_obs_treat),\n      p_obs_treat = ifelse(id_method == \"OLS\", NA, p_obs_treat),\n      iv_strength = ifelse(id_method != \"IV\", NA, iv_strength)\n    ) %>% \n    distinct() %>% #to erase the duplicates due to iv_strength in non-iv id_methods\n    arrange(id_method, n_days) %>% \n    crossing(rep_id = 1:n_iter) %>%\n    select(-rep_id) \n  \n  return(sim_param_clean)\n} \n\nsim_param_evol <- prepare_sim_param(sim_param_unique, n_iter = 1)\n\n# write_csv(sim_param, \"../Outputs/sim_param.csv\")\n\n\n\nRunning the simulation\nWe can then run the simulations for each set of parameter, using a pmap_dfr function. We wrote a function to do that while saving intermediary outcomes (every save_every iteration). name_save is the name to use to save an intermediary outcome (to which we add _intermediary and the iteration number).\n\n\nrun_all_sim <- function(data, sim_param, save_every, name_save) {\n  output <- NULL\n  future::plan(multicore)\n  \n  tic()\n  for (i in 1:ceiling(nrow(sim_param)/save_every)) {\n    params_slice <- sim_param %>% \n      slice((1 + save_every*(i-1)):(save_every*i))\n    \n    with_progress({\n      p <- progressor(steps = nrow(params_slice), on_exit = FALSE)\n      \n      intermediary_output <- future_pmap_dfr(\n        params_slice,\n        compute_simulation,\n        data = data,\n        progressbar = p,\n        .options = furrr_options(seed = TRUE)\n      )\n    })\n    \n    print(paste(\"Iteration =\", i*save_every))\n    output <- output %>% rbind(intermediary_output)\n    saveRDS(\n      intermediary_output, \n      here(\"R\", \"Outputs\", \"Sim_save\", str_c(name_save, \"_intermediary_\", i*save_every,\".RDS\"))\n    )\n  }\n  toc()\n  return(output)\n}\n\nsim_evol_large <- run_all_sim(nmmaps_data, sim_param_evol, save_every = 10000, \"sim_evol\")\n\n# beepr::beep(1)\n\n# saveRDS(sim_evol_large, here(\"R\", \"Outputs\", \"sim_evol_large.RDS\"))\n\n\n\nSummarising the results\nWe then build the function summarise_simulations to summarize our results, computing power, type M and so on for each set of parameters. Note that this function can only take as input a data frame produced by compute_simulation (or a mapped version of this function).\n\n\nsummarise_simulations <- function(data) {\n  \n  data %>% \n    mutate(\n      CI_low = estimate + se*qnorm((1-0.95)/2),\n      CI_high = estimate - se*qnorm((1-0.95)/2),\n      length_CI = abs(CI_high - CI_low),\n      covered = (true_effect > CI_low & true_effect < CI_high), \n      covered_signif = ifelse(p_value > 0.05, NA, covered) #to consider only significant estimates\n    ) %>% \n    group_by(formula, quasi_exp, n_days, n_cities, p_obs_treat, percent_effect_size, id_method, iv_strength) %>%\n    summarise(\n      power = mean(p_value <= 0.05, na.rm = TRUE)*100, \n      type_m = mean(ifelse(p_value <= 0.05, abs(estimate/true_effect), NA), na.rm = TRUE),\n      type_s = sum(ifelse(p_value <= 0.05, sign(estimate) != sign(true_effect), NA), na.rm = TRUE)/n()*100,\n      coverage_rate = mean(covered_signif, na.rm = TRUE)*100,\n      coverage_rate_all = mean(covered, na.rm = TRUE)*100,\n      # mse = mean((estimate - true_effect)^2, na.rm = TRUE),\n      # normalized_bias = mean(abs((estimate - true_effect/true_effect)), na.rm = TRUE),\n      # estimate_true_ratio = mean(abs(estimate/true_effect), na.rm = TRUE),\n      mean_f_stat = mean(f_stat, na.rm = TRUE),\n      mean_signal_to_noise = mean(estimate/length_CI, na.rm = TRUE),\n      .groups  = \"drop\"\n    ) %>% \n    ungroup() %>% \n    mutate(\n      outcome = str_extract(formula, \"^[^\\\\s~]+(?=\\\\s?~)\"),\n      n_days = as.integer(n_days),\n      n_cities = as.integer(n_cities)\n    )\n} \n\n\n\nWe then run this function.\n\n\nsummary_evol_large <- summarise_simulations(sim_evol_large) %>% \n  mutate(outcome = fct_relevel(outcome, \"copd_age_65_75\", \"resp_total\", \"death_total\"))\n\n# saveRDS(summary_evol_large, here(\"R\", \"Outputs\", \"summary_evol_large.RDS\"))\n\n\n\nSmall number of observations\nWe then replicate this analysis for a smaller and more realistic baseline number of observations (10 cities and 1000 days).\n\n\nsim_param_base_small <- tibble(\n  n_days = 1000,\n  n_cities = 10,\n  p_obs_treat = 0.5,\n  percent_effect_size = 1, \n  iv_strength = 0.5,\n  formula = \"death_total ~ treated + temperature + temperature_squared | city + month^year + weekday\"\n)\n\nsim_param_unique_small <- \n  map_dfr(\n    vect_of_vect_param, \n    add_values_param, \n    df = sim_param_base\n  ) %>% \n  distinct() \n\nsim_param_evol_small <- prepare_sim_param(sim_param_unique_small, n_iter = 1) %>% \n  filter(!(id_method == \"RDD\" & p_obs_treat <= 0.01)) \n\nsim_evol_small <- run_all_sim(nmmaps_data, sim_param_evol_small, save_every = 10, \"sim_evol_small\")\n\n# saveRDS(sim_evol_small, here(\"R\", \"Outputs\", \"sim_evol_small.RDS\"))\n\nsummary_evol_small <- summarise_simulations(sim_evol_small) %>% \n  mutate(outcome = fct_relevel(outcome, \"copd_age_65_75\", \"resp_total\", \"death_total\"))\n\n# saveRDS(summary_evol_small, here(\"R\", \"Outputs\", \"summary_evol_small.RDS\"))\n\n\n\nDecomposing the number of observations into number of cities and days\nIn this section, we wonder whether only the total number of observations maters or whether the ratio between number of cities and length of the study matters. We want to see whether decreasing the number of cities studied while keeping the number of observations constant (thus increasing the number of days) affects power and type M error. We thus run several simulations with an identical number of observations but different numbers of cities/days. We repeat this for 3 different number of observations (1000, 2000 and 4000) to check the robustness of our findings.\nWe first define the set of parameters:\n\n\nsim_param_decomp_nobs <- \n  tibble(n_cities = c(1, 3, 5, 10, 15, 25, 34)) %>%\n  crossing(n_obs = c(1000, 2000, 3000)) %>%\n  mutate(n_days = round(n_obs/n_cities)) %>% \n  select(-n_obs) %>% \n  full_join(sim_param_base, by = c(\"n_cities\", \"n_days\")) %>% \n  fill(everything(), .direction = \"updown\") %>% \n  anti_join(#because sim_param_base not in the exact set of param we want here\n    sim_param_base,\n    by = c(\"n_cities\", \"n_days\", \"p_obs_treat\", \"percent_effect_size\", \"iv_strength\", \"formula\")\n  ) %>% \n  prepare_sim_param(n_iter = 1000) \n\n\n\nWe then run the simulations.\n\n\nsim_decomp_nobs <- run_all_sim(nmmaps_data, sim_param_decomp_nobs, 10000, \"sim_decomp_nobs\")\n\n# saveRDS(sim_decomp_nobs, here(\"R\", \"Outputs\", \"sim_decomp_nobs.RDS\"))\n\nsummary_decomp_nobs <- summarise_simulations(sim_decomp_nobs) %>% \n    mutate(decomp_var = \"n_obs\")\n# saveRDS(summary_decomp_nobs, here(\"R\", \"Outputs\", \"summary_decomp_nobs.RDS\"))\n\n\n\nDecomposing the number of treated into number of observations and proportion of treated\nWe now then want to test whether we can combine information about the proportion of treated and the number of observations (into the number of treated). To do so, we use a methodology analog to the previous one.\nWe first define the set of parameters:\n\n\nsim_param_decomp_ptreat <- \n  tibble(p_obs_treat = c(0.01, 0.025, 0.05, 0.1, 0.25, 0.5)) %>%\n  crossing(n_treat = c(500, 1000, 2000)) %>%\n  mutate(\n    n_obs = round(n_treat/p_obs_treat),\n    n_cities = 50, #needs to be big enough\n    n_days = round(n_obs/n_cities)\n  ) %>% \n  select(-n_obs, -n_treat) %>% \n  full_join(sim_param_base, by = c(\"n_cities\", \"n_days\", \"p_obs_treat\")) %>% \n  fill(everything(), .direction = \"updown\") %>% \n  anti_join(#because sim_param_base not in the exact set of param we want here\n    sim_param_base,\n    by = c(\"n_cities\", \"n_days\", \"p_obs_treat\", \"percent_effect_size\", \"iv_strength\", \"formula\")\n  ) %>% \n  prepare_sim_param(n_iter = 1000) %>% \n  filter(id_method != \"OLS\")\n\n\n\nWe then run the simulations.\n\n\nsim_decomp_ptreat <-  run_all_sim(nmmaps_data, sim_param_decomp_ptreat, 10000, \"sim_decomp_ptreat\")\n\n# saveRDS(sim_decomp_ptreat, here(\"R\", \"Outputs\", \"sim_decomp_ptreat.RDS\"))\n\n\nsummary_decomp_ptreat <- summarise_simulations(sim_decomp_ptreat) %>% \n    mutate(decomp_var = \"n_treat\")\n# saveRDS(summary_decomp_ptreat, here(\"R\", \"Outputs\", \"summary_decomp_ptreat.RDS\"))\n\nsummary_decomp <- summary_decomp_nobs %>% \n    rbind(summary_decomp_ptreat)\n\n# saveRDS(summary_decomp, here(\"R\", \"Outputs\", \"summary_decomp.RDS\"))\n\n\n\nUsual values in the literature\nIn previous simulations, we varied all parameters, choosing somehow arbitrary values for the base parameters. In this section, we pick base values from the literature, for each identification method.\nRDD\n\n\nsim_param_base_usual_RDD <- tibble(\n  n_days = 3652,\n  n_cities = 1,\n  p_obs_treat = 0.012, #approximately 43/3652\n  percent_effect_size = 12, \n  iv_strength = NA,\n  formula = \"death_total ~ treated + temperature + temperature_squared | city + month^year + weekday\"\n)\n\nvect_n_days <- 3652\nvect_p_obs_treat <- c(0.012, 0.02, 0.05, 0.1)\nvect_percent_effect_size <- c(2, 5, 12, 20)\nvect_iv_strength <- NA\nvect_formula <- c(\n  \"death_total ~ treated + temperature + temperature_squared | city + month^year + weekday\",\n  \"resp_total ~ treated + temperature + temperature_squared | city + month^year + weekday\"\n)\n\nsim_param_unique_usual_RDD <- \n  map_dfr(\n    vect_of_vect_param, \n    add_values_param, \n    df = sim_param_base_usual_RDD\n  ) %>% \n  distinct() \n\nsim_param_evol_usual_RDD <- prepare_sim_param(sim_param_unique_usual_RDD, n_iter = 3000) %>% \n  filter(id_method == \"RDD\") %>% \n  mutate(p_obs_treat = p_obs_treat*5) #Because divide by 5 in prepare_sim_param\n\n\n\nReduced form\n\n\nsim_param_base_usual_reduced <- tibble(\n  n_days = 2200,\n  n_cities = 5,\n  p_obs_treat = 0.004, #about 45/(2200*5),\n  percent_effect_size = 11, \n  iv_strength = NA,\n  formula = \"resp_total ~ treated + temperature + temperature_squared | city + month^year + weekday\"\n)\n\nvect_n_days <- 2200\nvect_p_obs_treat <- c(0.004, 0.01, 0.02, 0.05, 0.1)\nvect_percent_effect_size <- c(2, 5, 11, 20)\nvect_iv_strength <- NA\nvect_formula <- c(\n  # \"death_total ~ treated\",\n  \"resp_total ~ treated + temperature + temperature_squared | city + month^year + weekday\",\n  \"death_total ~ treated + temperature + temperature_squared | city + month^year + weekday\",\n  \"copd_age_65_75 ~ treated + temperature + temperature_squared | city + month^year + weekday\"\n)\n\nsim_param_unique_usual_reduced <- \n  map_dfr(\n    vect_of_vect_param, \n    add_values_param, \n    df = sim_param_base_usual_reduced\n  ) %>% \n  distinct() \n\nsim_param_evol_usual_reduced <- prepare_sim_param(sim_param_unique_usual_reduced, n_iter = 3000) %>% \n  filter(id_method == \"reduced_form\") \n\n\n\nIV\n\n\nsim_param_base_usual_IV <- tibble(\n  n_days = 2500,\n  n_cities = 40,\n  p_obs_treat = 0.5,\n  percent_effect_size = 1.5, \n  iv_strength = 0.5,\n  formula = \"death_total ~ treated + temperature + temperature_squared | city + month^year + weekday\"\n)\n\nvect_n_days <- 2500\nvect_p_obs_treat <- 0.5\nvect_percent_effect_size <- 1.5\nvect_iv_strength <- c(0.01, 0.1, 0.2, 0.5, 0.7)\nvect_formula <- c(\n  # \"death_total ~ treated\",\n  \"resp_total ~ treated + temperature + temperature_squared | city + month^year + weekday\",\n  \"death_total ~ treated + temperature + temperature_squared | city + month^year + weekday\",\n  \"copd_age_65_75 ~ treated + temperature + temperature_squared | city + month^year + weekday\"\n)\n\nsim_param_unique_usual_IV <- \n  map_dfr(\n    vect_of_vect_param, \n    add_values_param, \n    df = sim_param_base_usual_IV\n  ) %>% \n  distinct() \n\nsim_param_evol_usual_IV <- prepare_sim_param(sim_param_unique_usual_IV, n_iter = 3000) %>% \n  filter(id_method == \"IV\") \n\n\n\nRunning simulations\n\n\nsim_param_evol_usual <- sim_param_evol_usual_RDD %>% \n  bind_rows(sim_param_evol_usual_reduced) %>% \n  bind_rows(sim_param_evol_usual_IV)\n\nsim_evol_usual <- run_all_sim(nmmaps_data, sim_param_evol_usual, save_every = 10000, \"sim_evol_usual\")\n\n# saveRDS(sim_evol_usual, here(\"R\", \"Outputs\", \"sim_evol_usual.RDS\"))\n\nsummary_evol_usual <- summarise_simulations(sim_evol_usual) %>% \n  mutate(outcome = fct_relevel(outcome, \"copd_age_65_75\", \"resp_total\", \"death_total\"))\n\n# saveRDS(summary_evol_usual, here(\"R\", \"Outputs\", \"summary_evol_usual.RDS\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
      "last_modified": "2021-06-23T13:04:36+02:00"
    }
  ],
  "collections": []
}
